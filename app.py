from flask import Flask, jsonify, request
import json
import datetime
import requests
import bs4 as bs
import os
import random

app = Flask(__name__)

# ============================================
# ğŸ¯ CONFIGURATION - MODIFIEZ ICI LA NICHE
# ============================================
TARGET_NICHE = "ç¾é£Ÿ"  # â† CHANGEZ ICI POUR UNE AUTRE NICHE

# Configuration flexible des pÃ©riodes
TIME_PERIODS = {
    "24h": 86400,      # 24 heures
    "48h": 172800,     # 48 heures  
    "3days": 259200,   # 3 jours
    "7days": 604800    # 7 jours
}

# ğŸ”¥ MOTS-CLÃ‰S POUR LA NICHE SÃ‰LECTIONNÃ‰E
# Ajoutez ou modifiez les mots-clÃ©s selon votre niche
def get_niche_keywords(niche):
    """Retourne les mots-clÃ©s pour la niche sÃ©lectionnÃ©e"""
    keywords_map = {
        # CUISINE / NOURRITURE
        "ç¾é£Ÿ": ["ç¾é£Ÿ", "æ–™ç†", "çƒ¹é¥ª", "é£Ÿè°±", "å°åƒ", "ç¾å‘³", "å¨è‰º"],
        
        # BEAUTÃ‰
        "ç¾å¦†": ["ç¾å¦†", "åŒ–å¦†", "æŠ¤è‚¤", "å½©å¦†", "ç¾å®¹", "å£çº¢", "çœ¼å¦†"],
        
        # VOYAGE
        "æ—…è¡Œ": ["æ—…è¡Œ", "æ—…æ¸¸", "é£æ™¯", "æ™¯ç‚¹", "æ¢ç´¢", "æ—…æ‹", "åº¦å‡"],
        
        # MODE
        "æ—¶å°š": ["æ—¶å°š", "ç©¿æ­", "æœè£…", "æ½®æµ", "æ­é…", "æ—¶è£…", "é€ å‹"],
        
        # DANSE
        "èˆè¹ˆ": ["èˆè¹ˆ", "è·³èˆ", "èˆæ­¥", "ç¼–èˆ", "èˆè¹ˆæ•™å­¦", "è¡—èˆ", "ç°ä»£èˆ"],
        
        # MUSIQUE
        "éŸ³ä¹": ["éŸ³ä¹", "æ­Œæ›²", "æ¼”å”±", "ä¹å™¨", "éŸ³ä¹æ•™å­¦", "ç¿»å”±", "åŸåˆ›"],
        
        # SPORT
        "è¿åŠ¨": ["è¿åŠ¨", "å¥èº«", "é”»ç‚¼", "ä½“è‚²", "è®­ç»ƒ", "è·‘æ­¥", "ç‘œä¼½"],
        
        # HUMOUR
        "æç¬‘": ["æç¬‘", "å¹½é»˜", "æ®µå­", "å–œå‰§", "æ¶æ", "æœ‰è¶£", "çˆ†ç¬‘"],
        
        # ANIMAUX
        "å® ç‰©": ["å® ç‰©", "çŒ«å’ª", "ç‹—ç‹—", "èŒå® ", "åŠ¨ç‰©", "çŒ«", "ç‹—"],
        
        # FITNESS
        "å¥èº«": ["å¥èº«", "é”»ç‚¼", "è‚Œè‚‰", "å‡è‚¥", "å¡‘å½¢", "è¿åŠ¨", "è®­ç»ƒ"],
        
        # GAMING
        "æ¸¸æˆ": ["æ¸¸æˆ", "ç”µç«", "æ‰‹æ¸¸", "æ”»ç•¥", "ç›´æ’­", "ç‹è€…", "åƒé¸¡"],
        
        # TECH
        "ç§‘æŠ€": ["ç§‘æŠ€", "æ•°ç ", "æ‰‹æœº", "ç”µè„‘", "AI", "æŠ€æœ¯", "åˆ›æ–°"]
    }
    
    return keywords_map.get(niche, [niche])

# Nom de la niche actuelle
def get_niche_name(niche):
    """Retourne le nom franÃ§ais de la niche"""
    names = {
        "ç¾é£Ÿ": "Cuisine/Nourriture",
        "ç¾å¦†": "BeautÃ©", 
        "æ—…è¡Œ": "Voyage",
        "æ—¶å°š": "Mode",
        "èˆè¹ˆ": "Danse",
        "éŸ³ä¹": "Musique",
        "è¿åŠ¨": "Sport",
        "æç¬‘": "Humour",
        "å® ç‰©": "Animaux",
        "å¥èº«": "Fitness",
        "æ¸¸æˆ": "Gaming",
        "ç§‘æŠ€": "Tech"
    }
    return names.get(niche, "Inconnu")
# ============================================

def is_within_period(timestamp, period_seconds):
    """VÃ©rifie si le timestamp est dans la pÃ©riode donnÃ©e"""
    now = datetime.datetime.now().timestamp()
    return (now - timestamp) <= period_seconds

def get_cache_key():
    """GÃ©nÃ¨re une clÃ© de cache basÃ©e sur la date pour Ã©viter le spam"""
    today = datetime.date.today().strftime("%Y-%m-%d")
    return f"{TARGET_NICHE}_{today}"

def scrape_with_fallback(max_videos=50, min_videos=10):
    """Scrape avec systÃ¨me de fallback intelligent pour LA niche sÃ©lectionnÃ©e"""
    
    # RÃ©cupÃ©rer les mots-clÃ©s pour la niche sÃ©lectionnÃ©e
    search_terms = get_niche_keywords(TARGET_NICHE)
    periods = ["24h", "48h", "3days", "7days"]
    
    all_results = []
    attempts = []
    
    print(f"ğŸ¯ Recherche pour la niche: {TARGET_NICHE} ({get_niche_name(TARGET_NICHE)})")
    print(f"ğŸ“ Mots-clÃ©s utilisÃ©s: {search_terms}")
    
    for period in periods:
        for search_term in search_terms:
            try:
                result = scrape_niche_period(search_term, TIME_PERIODS[period])
                attempts.append({
                    "term": search_term,
                    "period": period,
                    "count": len(result) if isinstance(result, list) else 0,
                    "status": "success" if isinstance(result, list) else "error"
                })
                
                if isinstance(result, list) and result:
                    all_results.extend(result)
                    
                    # Si on a assez de vidÃ©os, on s'arrÃªte
                    if len(all_results) >= min_videos:
                        break
                        
            except Exception as e:
                attempts.append({
                    "term": search_term,
                    "period": period,
                    "count": 0,
                    "status": f"error: {str(e)}"
                })
                continue
        
        # Si on a assez de vidÃ©os, on s'arrÃªte
        if len(all_results) >= min_videos:
            break
    
    # Supprimer les doublons basÃ©s sur l'URL
    seen_urls = set()
    unique_results = []
    for video in all_results:
        video_url = video.get('video_url', '')
        if video_url and video_url not in seen_urls:
            seen_urls.add(video_url)
            unique_results.append(video)
    
    # MÃ©langer et limiter
    random.shuffle(unique_results)
    final_results = unique_results[:max_videos]
    
    return {
        "success": True,
        "niche": TARGET_NICHE,
        "niche_name": get_niche_name(TARGET_NICHE),
        "keywords_used": search_terms,
        "count": len(final_results),
        "videos": final_results,
        "search_attempts": attempts,
        "fallback_used": len([a for a in attempts if a["status"] == "success"]) > 1
    }

def scrape_niche_period(search_term, period_seconds):
    """Scrape une niche pour une pÃ©riode donnÃ©e"""
    topic_api = 'https://aweme-hl.snssdk.com/aweme/v1/hot/search/video/list/?hotword='
    
    try:
        response = requests.get(topic_api + search_term, timeout=15)
        soup = bs.BeautifulSoup(response.content, 'html.parser')
        data = json.loads(soup.text)
        videos = data['aweme_list']
    except Exception as e:
        raise Exception(f"Erreur API pour '{search_term}': {str(e)}")
    
    # Filtrer les vidÃ©os de la pÃ©riode
    filtered_videos = [v for v in videos if is_within_period(v['create_time'], period_seconds)]
    
    # Extraire URLs et thumbnails
    results = []
    for video in filtered_videos:
        try:
            # RÃ©cupÃ©rer l'URL de la vidÃ©o
            video_url = None
            try:
                video_urls = video['video']['download_addr']['url_list']
                video_url = next((url for url in video_urls if 'default' in url), video_urls[0] if video_urls else None)
            except:
                pass
            
            # RÃ©cupÃ©rer le thumbnail
            thumbnail_url = None
            try:
                thumbnail_url = video['video']['cover']['url_list'][0]
            except:
                pass
            
            if video_url or thumbnail_url:  # Au moins une URL valide
                results.append({
                    "video_url": video_url,
                    "thumbnail_url": thumbnail_url,
                    "timestamp": video['create_time'],
                    "desc": video.get('desc', ''),
                    "author": video['author'].get('nickname', ''),
                    "search_term": search_term,
                    "age_hours": round((datetime.datetime.now().timestamp() - video['create_time']) / 3600, 1)
                })
        except:
            continue
    
    return results

@app.route('/api/scrape')
def api_scrape():
    """API endpoint pour scraper la niche configurÃ©e avec fallback"""
    result = scrape_with_fallback()
    return jsonify(result)

@app.route('/api/scrape/urls-only')
def api_urls_only():
    """API endpoint qui retourne seulement les URLs avec fallback"""
    result = scrape_with_fallback()
    
    if not result["success"]:
        return jsonify(result)
    
    # Extraire seulement les URLs
    urls_data = {
        "success": True,
        "niche": TARGET_NICHE,
        "niche_name": get_niche_name(TARGET_NICHE),
        "keywords_used": result.get("keywords_used", []),
        "count": result["count"],
        "video_urls": [v["video_url"] for v in result["videos"] if v["video_url"]],
        "thumbnail_urls": [v["thumbnail_url"] for v in result["videos"] if v["thumbnail_url"]],
        "fallback_used": result["fallback_used"]
    }
    
    return jsonify(urls_data)

@app.route('/api/scrape/fresh')
def api_fresh_only():
    """API endpoint pour les vidÃ©os des derniÃ¨res 24h uniquement"""
    try:
        result = scrape_niche_period(TARGET_NICHE, TIME_PERIODS["24h"])
        
        if not result:
            return jsonify({
                "success": False,
                "error": f"Aucune vidÃ©o fraÃ®che trouvÃ©e pour '{TARGET_NICHE}'"
            })
        
        return jsonify({
            "success": True,
            "niche": TARGET_NICHE,
            "count": len(result),
            "videos": result
        })
        
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})

@app.route('/')
def home():
    """Documentation de l'API et configuration actuelle"""
    current_keywords = get_niche_keywords(TARGET_NICHE)
    
    return jsonify({
        "message": "Douyin Scraper API - Niche Unique avec Mots-clÃ©s Multiples",
        "configuration": {
            "niche_actuelle": TARGET_NICHE,
            "nom_niche": get_niche_name(TARGET_NICHE),
            "mots_cles_utilises": current_keywords,
            "nombre_mots_cles": len(current_keywords)
        },
        "endpoints": {
            "/api/scrape": "DonnÃ©es complÃ¨tes avec systÃ¨me de fallback (RECOMMANDÃ‰)",
            "/api/scrape/urls-only": "URLs uniquement avec fallback (RECOMMANDÃ‰)",
            "/api/scrape/fresh": "VidÃ©os des derniÃ¨res 24h uniquement"
        },
        "fonctionnalites": {
            "niche_unique": f"Se concentre uniquement sur: {get_niche_name(TARGET_NICHE)}",
            "mots_cles_multiples": f"Utilise {len(current_keywords)} mots-clÃ©s pour cette niche",
            "fallback_intelligent": "Cherche sur plusieurs pÃ©riodes (24h, 48h, 3j, 7j)",
            "deduplication": "Supprime les vidÃ©os en double",
            "melange_aleatoire": "MÃ©lange les rÃ©sultats pour plus de diversitÃ©"
        },
        "comment_changer_niche": {
            "instruction": "Modifiez la variable TARGET_NICHE ligne 12 du code",
            "exemple": "TARGET_NICHE = 'ç¾å¦†'  # pour changer vers BeautÃ©",
            "niches_disponibles": {
                "ç¾é£Ÿ": "Cuisine (7 mots-clÃ©s)",
                "ç¾å¦†": "BeautÃ© (7 mots-clÃ©s)", 
                "æ—…è¡Œ": "Voyage (7 mots-clÃ©s)",
                "æ—¶å°š": "Mode (7 mots-clÃ©s)",
                "èˆè¹ˆ": "Danse (7 mots-clÃ©s)",
                "éŸ³ä¹": "Musique (7 mots-clÃ©s)",
                "è¿åŠ¨": "Sport (7 mots-clÃ©s)",
                "æç¬‘": "Humour (6 mots-clÃ©s)",
                "å® ç‰©": "Animaux (7 mots-clÃ©s)",
                "å¥èº«": "Fitness (7 mots-clÃ©s)",
                "æ¸¸æˆ": "Gaming (7 mots-clÃ©s)",
                "ç§‘æŠ€": "Tech (7 mots-clÃ©s)"
            }
        }
    })

@app.route('/health')
def health():
    """Health check pour Render"""
    return jsonify({
        "status": "healthy", 
        "timestamp": datetime.datetime.now().isoformat(),
        "current_niche": TARGET_NICHE
    })

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
